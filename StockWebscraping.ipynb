{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fde21970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A notebook that gets daily closing prices, calculates log returns, alpha, beta, and Sharpe Ratio\n",
    "#TODO: Scrape earnings reports so we have some more graphs to work with\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import twint\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "25ef76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrame(stockList, startDate, endDate):\n",
    "    stockDataFrame = pd.DataFrame(columns = stockList)\n",
    "    for stock in stockList:\n",
    "        stockDataFrame[stock] = yf.download(stock, start=startDate, end=endDate, progress=False)['Close']\n",
    "    return stockDataFrame\n",
    "\n",
    "def logReturns(stockDataFrame):\n",
    "    for stock in stockDataFrame.columns:\n",
    "        stockDataFrame[stock] = np.log(stockDataFrame[stock]) - np.log(stockDataFrame[stock].shift(1))\n",
    "    stockDataFrame.dropna(inplace=True)\n",
    "    return stockDataFrame\n",
    "\n",
    "#We use rolling alpha, beta in this case. Comparing with the SP500 for linear regression\n",
    "def marketAlphaBeta(logReturnDF, benchmarkDF):\n",
    "    alphaDataFrame = pd.DataFrame(columns = logReturnDF.columns, index=logReturnDF.index)\n",
    "    betaDataFrame = pd.DataFrame(columns = logReturnDF.columns, index=logReturnDF.index)\n",
    "    obs = logReturnDF.shape[0]\n",
    "    lagWindow = 30\n",
    "    for i in range((obs-lagWindow)):\n",
    "        for stock in logReturnDF.columns:\n",
    "            regressor = LinearRegression()\n",
    "            regressor.fit(benchmarkDF['^GSPC'].to_numpy()[i : i +lagWindow+1].reshape(-1,1), logReturnDF[stock].to_numpy()[i : i +lagWindow+1])\n",
    "            betaDataFrame[stock][i+lagWindow]  = regressor.coef_[0]\n",
    "            alphaDataFrame[stock][i+lagWindow]  = regressor.intercept_\n",
    "    alphaDataFrame.dropna(inplace=True)\n",
    "    betaDataFrame.dropna(inplace=True)\n",
    "    return alphaDataFrame, betaDataFrame\n",
    "\n",
    "#We use rolling Sharpe ratio in this case. We use 10 year Treasury Note (^TNX) yield as \"risk-free\" rate\n",
    "def rollingSharpeRatio(logReturnDF, logBenchmark):\n",
    "    sharpeDataFrame = pd.DataFrame(columns = logReturnDF.columns, index = logReturnDF.index)\n",
    "    obs = logReturnDF.shape[0]\n",
    "    lagWindow = 60\n",
    "    for i in range((obs-lagWindow)):\n",
    "        for stock in logReturnDF.columns:\n",
    "            netReturn = logReturnDF[stock][i : i +lagWindow+1].mean() - logBenchmark['^TNX'][i : i +lagWindow+1].mean()\n",
    "            stdDev = logReturnDF[stock][i : i +lagWindow+1].std()\n",
    "            sharpeDataFrame[stock][i+lagWindow]  = netReturn/stdDev\n",
    "    sharpeDataFrame.dropna(inplace=True)\n",
    "    return sharpeDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "76629b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables that we can modify to get our data\n",
    "memeStocks = ['AAPL','GOOG','TSLA','KO','OXY','BAC']\n",
    "benchmarks = ['^GSPC','^TNX']\n",
    "startDate = '2022-3-24'\n",
    "endDate = '2023-3-24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e26ff80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run once variables are filled out\n",
    "newFrame = createDataFrame(memeStocks, startDate, endDate)\n",
    "newFrame.to_csv(\"stockPrices.csv\")\n",
    "benchmarkFrame = createDataFrame(benchmarks, startDate, endDate)\n",
    "benchmarkFrame.to_csv(\"benchmarkPrices.csv\")\n",
    "logDataFrame = logReturns(newFrame)\n",
    "logDataFrame.to_csv(\"logReturnsStock.csv\")\n",
    "logBenchmark = logReturns(benchmarkFrame)\n",
    "logBenchmark.to_csv(\"logReturnsBenchmark.csv\")\n",
    "alphaFrame, betaFrame = marketAlphaBeta(logDataFrame, logBenchmark)\n",
    "alphaFrame.to_csv(\"alphas.csv\")\n",
    "betaFrame.to_csv(\"betas.csv\")\n",
    "sharpeDataFrame = rollingSharpeRatio(logDataFrame, logBenchmark)\n",
    "sharpeDataFrame.to_csv(\"sharpeRatios.csv\")\n",
    "newFrame = createDataFrame(memeStocks, startDate, endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6baf7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(newFrame, benchmarkFrame, left_index=True, right_index=True)\n",
    "df['Date'] = df.index\n",
    "df = pd.melt(df, id_vars=[i for i in df.columns.values if i not in memeStocks], value_vars=memeStocks, var_name='Ticker', value_name='Price')\n",
    "logDataFrame['Date'] = logDataFrame.index\n",
    "log_melted = pd.melt(logDataFrame, id_vars=['Date'],value_vars=memeStocks, var_name='Ticker', value_name='Price')\n",
    "df = pd.merge(df, log_melted, on=['Ticker','Date'], how='inner', suffixes=['_Stock','_Log_Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c0a926f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "def scrapeForDate(ticker,dates):\n",
    "    df = pd.DataFrame()\n",
    "    since = processDateRange(dates.shift(freq='-1D'))\n",
    "    until = processDateRange(dates)\n",
    "    for j,day in enumerate(since):\n",
    "        tweets_list = []\n",
    "        query_str = f'${ticker} lang:en since:{since[j]} until:{until[j]}'\n",
    "        for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query_str).get_items()):\n",
    "            if i>=60:\n",
    "                break\n",
    "            tweets_list.append([tweet.date, tweet.id, tweet.content])\n",
    "        temp = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "        df = pd.concat([df,temp])\n",
    "    return df\n",
    "\n",
    "def processDateRange(date_range):\n",
    "    dates = [datetime.strptime(str(date), '%Y-%m-%d %H:%M:%S') for date in date_range.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "    dates = [date.strftime('%Y-%m-%d') for date in dates]\n",
    "    return dates    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "96b73b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "dfs = []\n",
    "date_range = pd.date_range(start=startDate, end=endDate)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for ticker in memeStocks:\n",
    "        df = scrapeForDate(ticker, date_range)\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(dfs):\n",
    "    df['Ticker'] = memeStocks[i]\n",
    "    df.to_csv(f'Data/Tweets_new/{memeStocks[i]}_Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29842f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import os\n",
    "files = [os.path.join(f'{os.getcwd()}/Data/Tweets_new',path) for path in os.listdir('Data/Tweets')]\n",
    "tweets = [pd.read_csv(file,index_col=0,engine='python') for file in files]\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for i in range(len(tweets)):\n",
    "    tweets[i].dropna(inplace=True)\n",
    "    scores = []\n",
    "    for j, row in tweets[i].iterrows():\n",
    "        vs = analyzer.polarity_scores(row['Text'])['compound']\n",
    "        scores.append(vs)\n",
    "    tweets[i]['polarity_score'] = scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71052557",
   "metadata": {},
   "source": [
    "**Score Interpretation** <br>\n",
    "positive sentiment: compound score >= 0.05 <br>\n",
    "neutral sentiment: (compound score > -0.05) and (compound score < 0.05) <br>\n",
    "negative sentiment: compound score <= -0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcfe74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^TNX</th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price_Stock</th>\n",
       "      <th>Price_Log_Return</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.062507</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>174.720001</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.140153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007120</td>\n",
       "      <td>-0.006037</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>175.600006</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.199839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012182</td>\n",
       "      <td>-0.031579</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>178.960007</td>\n",
       "      <td>0.018954</td>\n",
       "      <td>0.220375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006314</td>\n",
       "      <td>-0.017655</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>177.770004</td>\n",
       "      <td>-0.006672</td>\n",
       "      <td>0.183917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.015776</td>\n",
       "      <td>-0.013234</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>174.610001</td>\n",
       "      <td>-0.017936</td>\n",
       "      <td>0.213395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.021259</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>174.309998</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.185623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.014617</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>178.440002</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>0.247065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.012631</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>175.059998</td>\n",
       "      <td>-0.019124</td>\n",
       "      <td>0.205817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.009764</td>\n",
       "      <td>0.020523</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>171.830002</td>\n",
       "      <td>-0.018623</td>\n",
       "      <td>0.113833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>172.139999</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.247603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ^GSPC      ^TNX       Date Ticker  Price_Stock  Price_Log_Return  \\\n",
       "0  0.005053  0.062507 2022-03-25   AAPL   174.720001          0.003727   \n",
       "1  0.007120 -0.006037 2022-03-28   AAPL   175.600006          0.005024   \n",
       "2  0.012182 -0.031579 2022-03-29   AAPL   178.960007          0.018954   \n",
       "3 -0.006314 -0.017655 2022-03-30   AAPL   177.770004         -0.006672   \n",
       "4 -0.015776 -0.013234 2022-03-31   AAPL   174.610001         -0.017936   \n",
       "5  0.003404  0.021259 2022-04-01   AAPL   174.309998         -0.001720   \n",
       "6  0.008058  0.014617 2022-04-04   AAPL   178.440002          0.023417   \n",
       "7 -0.012631  0.057987 2022-04-05   AAPL   175.059998         -0.019124   \n",
       "8 -0.009764  0.020523 2022-04-06   AAPL   171.830002         -0.018623   \n",
       "9  0.004244  0.016347 2022-04-07   AAPL   172.139999          0.001802   \n",
       "\n",
       "   polarity_score  \n",
       "0        0.140153  \n",
       "1        0.199839  \n",
       "2        0.220375  \n",
       "3        0.183917  \n",
       "4        0.213395  \n",
       "5        0.185623  \n",
       "6        0.247065  \n",
       "7        0.205817  \n",
       "8        0.113833  \n",
       "9        0.247603  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tweets)):\n",
    "    tweets[i]['Datetime'] = pd.to_datetime(tweets[i]['Datetime'])\n",
    "    tweets[i]['Datetime'] = tweets[i]['Datetime'].dt.date\n",
    "    tweets[i].rename(columns={\"Datetime\": \"Date\"},inplace=True)\n",
    "\n",
    "tweet_df = pd.DataFrame()\n",
    "for i in range(len(tweets)):    \n",
    "    temp=tweets[i].groupby('Date')['polarity_score'].mean().reset_index()\n",
    "    temp['Ticker']=tweets[i]['Ticker'].values[0]\n",
    "    tweet_df=pd.concat([tweet_df, temp])\n",
    "tweet_df['Date'] = pd.to_datetime(tweet_df['Date'])\n",
    "\n",
    "df = pd.merge(df, tweet_df, on=['Date','Ticker'], how='inner')\n",
    "df.to_csv('finalizedDataset.csv')\n",
    "\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d53292f4fdbc407f3751602e47416b1da2b74024acf0fb5ba3434bfe364ec9bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
